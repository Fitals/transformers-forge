# üî¨ Benchmarks ‚Äî Transformers Forge

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π Forge.

## üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ benchmarks

### EMA Benchmark

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å EMA –∏ –±–µ–∑ EMA.

**–ó–∞–ø—É—Å–∫:**
```bash
python benchmarks/ema_benchmark.py
```

**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** ~2-5 –º–∏–Ω—É—Ç –Ω–∞ CPU

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç:**
- Final eval loss —Å EMA –∏ –±–µ–∑
- –£–ª—É—á—à–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

---

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

| Benchmark | –£–ª—É—á—à–µ–Ω–∏–µ | –°—Ç–∞—Ç—É—Å |
|-----------|-----------|--------|
| EMA (synthetic data) | +1-5% | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| EMA (GPT-2 fine-tuning) | üî¥ –ü—Ä–µ–¥—Å—Ç–æ–∏—Ç | –¢—Ä–µ–±—É–µ—Ç GPU |
| Layer Freezing memory | üî¥ –ü—Ä–µ–¥—Å—Ç–æ–∏—Ç | –¢—Ä–µ–±—É–µ—Ç GPU |

---

## üîß –ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–π benchmark

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `benchmarks/your_benchmark.py`
2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `run_benchmark()`
3. –î–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —ç—Ç–æ—Ç README

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** –î–µ–∫–∞–±—Ä—å 2025
