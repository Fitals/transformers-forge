# EMA (Exponential Moving Average)

**–ú–æ–¥—É–ª—å:** `transformers.ema`

EMA –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–≥–ª–∞–∂–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ã—á–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é generalization —á–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –æ–±—É—á–µ–Ω–∏—è.

---

## üìä –ó–∞—á–µ–º –Ω—É–∂–µ–Ω EMA?

| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ EMA |
|----------|-------------|
| –í–µ—Å–∞ "–ø—Ä—ã–≥–∞—é—Ç" –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ batch | EMA —Å–≥–ª–∞–∂–∏–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è |
| –®—É–º –≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞—Ö | –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —É–±–∏—Ä–∞–µ—Ç —à—É–º |
| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | EMA –≤–µ—Å–∞ –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã |

**–¢–∏–ø–∏—á–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** +1-3% –Ω–∞ eval –º–µ—Ç—Ä–∏–∫–∞—Ö*

> ‚ö†Ô∏è **–í–∞–∂–Ω–æ (v1.1.0):** –£–ª—É—á—à–µ–Ω–∏–µ +1-3% –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è –Ω–∞ **–º–æ–¥–µ–ª—è—Ö >1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** –ø—Ä–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ (10k+ steps). –ù–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö –º–æ–¥–µ–ª—è—Ö —ç—Ñ—Ñ–µ–∫—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º. –°–º. [RESEARCH.md](/docs/RESEARCH.md) –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.

---

## üîß –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```python
from transformers import Trainer
from transformers.ema import EMACallback

# –°–æ–∑–¥–∞—ë–º callback
ema_callback = EMACallback(decay=0.999)

# –î–æ–±–∞–≤–ª—è–µ–º –≤ Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    callbacks=[ema_callback]
)

# –û–±—É—á–∞–µ–º
trainer.train()

# –ü—Ä–∏–º–µ–Ω—è–µ–º EMA –≤–µ—Å–∞ (–±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ!)
ema_callback.apply_ema(model)
```

---

## üìñ API Reference

### EMACallback

```python
class EMACallback(TrainerCallback):
    def __init__(
        self,
        decay: float = 0.999,
        update_after_step: int = 0,
        update_every: int = 1
    )
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `decay` | float | 0.999 | –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è. –í—ã—à–µ = –º–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è |
| `update_after_step` | int | 0 | –ù–∞—á–∞—Ç—å EMA –ø–æ—Å–ª–µ N —à–∞–≥–æ–≤ (warmup) |
| `update_every` | int | 1 | –û–±–Ω–æ–≤–ª—è—Ç—å –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤ |

**–ú–µ—Ç–æ–¥—ã:**

| –ú–µ—Ç–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ |
|-------|----------|
| `apply_ema(model)` | –ü—Ä–∏–º–µ–Ω–∏—Ç—å EMA –≤–µ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ |
| `restore_original(model)` | –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ |
| `get_ema_state()` | –ü–æ–ª—É—á–∏—Ç—å EMA state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è |
| `load_ema_state(state_dict)` | –ó–∞–≥—Ä—É–∑–∏—Ç—å EMA state |

---

### EMAModel

```python
class EMAModel:
    def __init__(self, model, decay: float = 0.999)
```

–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è EMA –≤–µ—Ä—Å–∏–µ–π –º–æ–¥–µ–ª–∏.

**–ü—Ä–∏–º–µ—Ä:**

```python
from transformers.ema import EMAModel

ema_model = EMAModel(model, decay=0.999)

# –û–±—É—á–µ–Ω–∏–µ
for batch in dataloader:
    outputs = ema_model.model(batch)
    loss.backward()
    optimizer.step()
    ema_model.update()  # –û–±–Ω–æ–≤–ª—è–µ–º EMA

# –î–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º EMA –≤–µ—Å–∞
with ema_model.use_ema():
    outputs = ema_model.model(inputs)
```

---

### –£—Ç–∏–ª–∏—Ç—ã

#### compute_optimal_decay

```python
def compute_optimal_decay(
    total_steps: int,
    target_half_life_steps: int = None
) -> float
```

–í—ã—á–∏—Å–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π decay –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –æ–±—É—á–µ–Ω–∏—è.

```python
from transformers.ema import compute_optimal_decay

decay = compute_optimal_decay(total_steps=10000)
print(f"Recommended decay: {decay}")  # ~0.9993
```

#### print_ema_info

```python
def print_ema_info(decay: float, total_steps: int)
```

–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ EMA.

```python
from transformers.ema import print_ema_info

print_ema_info(decay=0.999, total_steps=10000)
# ==================================================
# EMA CONFIGURATION
# ==================================================
# Decay:                    0.999
# Half-life:                693 steps
# ...
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ decay

| –î–ª–∏–Ω–∞ –æ–±—É—á–µ–Ω–∏—è | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π decay |
|----------------|---------------------|
| 1,000 —à–∞–≥–æ–≤ | 0.99 |
| 10,000 —à–∞–≥–æ–≤ | 0.999 |
| 100,000 —à–∞–≥–æ–≤ | 0.9999 |

**–ü—Ä–∞–≤–∏–ª–æ:** –ß–µ–º –¥–ª–∏–Ω–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ, —Ç–µ–º –≤—ã—à–µ decay.

---

## üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ EMA

```python
import torch

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
ema_state = ema_callback.get_ema_state()
torch.save(ema_state, "ema_weights.pt")

# –ó–∞–≥—Ä—É–∑–∫–∞
ema_state = torch.load("ema_weights.pt")
ema_callback.load_ema_state(ema_state)
ema_callback.apply_ema(model)
```

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. **–ü–∞–º—è—Ç—å:** EMA —Ç—Ä–µ–±—É–µ—Ç ~2x –ø–∞–º—è—Ç–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤
2. **GPU:** EMA state —Ö—Ä–∞–Ω–∏—Ç—Å—è –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
3. **–†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:** EMA –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ

---

## üìö –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞

EMA –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ **Polyak averaging** (1990):

```
Œ∏_ema = Œ≤ √ó Œ∏_ema + (1-Œ≤) √ó Œ∏_current
```

–ì–¥–µ:
- `Œ∏_ema` ‚Äî EMA –≤–µ—Å–∞
- `Œ∏_current` ‚Äî —Ç–µ–∫—É—â–∏–µ –≤–µ—Å–∞
- `Œ≤` ‚Äî decay (–æ–±—ã—á–Ω–æ 0.999)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤:
- Stable Diffusion
- DALL-E
- –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ image generation –º–æ–¥–µ–ª–µ–π
