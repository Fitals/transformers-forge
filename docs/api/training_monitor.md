# Training Monitor

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ:** `transformers.training_monitor`

Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ¸ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.

---

## ğŸ“Š Ğ—Ğ°Ñ‡ĞµĞ¼ Ğ½ÑƒĞ¶ĞµĞ½ Training Monitor?

| ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° | Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ |
|----------|---------|
| ĞĞµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ | `estimate_model_memory()` |
| Ğ“Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ²Ğ·Ñ€Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ/Ğ¸ÑÑ‡ĞµĞ·Ğ°ÑÑ‚ | `check_gradient_health()` |
| Ğ¥Ğ¾Ñ‡Ñƒ Ğ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ | `MonitorCallback` |

---

## ğŸ”§ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

```python
from transformers import Trainer
from transformers import MonitorCallback, print_model_info

# Ğ’Ñ‹Ğ²ĞµÑÑ‚Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
print_model_info(model)

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ² Trainer
trainer = Trainer(
    model=model,
    args=args,
    callbacks=[MonitorCallback(check_gradients=True)]
)
```

---

## ğŸ“– API Reference

### Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

#### count_parameters

```python
def count_parameters(
    model,
    trainable_only: bool = False
) -> int
```

ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

```python
from transformers import count_parameters

total = count_parameters(model)
trainable = count_parameters(model, trainable_only=True)
print(f"Total: {total:,}, Trainable: {trainable:,}")
```

---

#### format_param_count

```python
def format_param_count(count: int) -> str
```

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² (1.5B, 7M, 3K).

```python
from transformers import format_param_count

print(format_param_count(1_500_000_000))  # "1.50B"
print(format_param_count(7_000_000))       # "7.00M"
```

---

#### get_parameter_breakdown

```python
def get_parameter_breakdown(model) -> List[Dict]
```

Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¿Ğ¾ ÑĞ»Ğ¾ÑĞ¼.

```python
from transformers import get_parameter_breakdown

breakdown = get_parameter_breakdown(model)
for layer in breakdown[:5]:
    print(f"{layer['name']}: {layer['params']:,} ({layer['dtype']})")
```

---

#### estimate_model_memory

```python
def estimate_model_memory(
    model,
    batch_size: int = 1,
    sequence_length: int = 512,
    precision: str = "fp16"
) -> Dict[str, float]
```

ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸.

```python
from transformers import estimate_model_memory

memory = estimate_model_memory(model, batch_size=4, sequence_length=2048)
print(f"Parameters: {memory['parameters_gb']:.2f} GB")
print(f"Gradients: {memory['gradients_gb']:.2f} GB")
print(f"Optimizer: {memory['optimizer_gb']:.2f} GB")
print(f"Total: {memory['total_estimated_gb']:.2f} GB")
```

---

#### print_model_info

```python
def print_model_info(
    model,
    show_breakdown: bool = False
)
```

ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

```python
from transformers import print_model_info

print_model_info(model)
# ================================================
# MODEL INFO
# ================================================
# Total parameters:     7,000,000,000 (7.00B)
# Trainable parameters: 1,000,000 (1.00M)
# Frozen parameters:    6,999,000,000
# Trainable ratio:      0.01%
# ================================================
# Memory Estimation (FP16):
# Parameters:           13.04 GB
# Gradients:            0.00 GB (frozen excluded)
# Optimizer (AdamW):    26.08 GB
# ================================================
```

---

### Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ

#### check_gradient_health

```python
def check_gradient_health(
    model,
    warn_threshold: float = 1.0,
    error_threshold: float = 10.0
) -> Dict
```

ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ².

```python
from transformers import check_gradient_health

# ĞŸĞ¾ÑĞ»Ğµ backward() Ğ½Ğ¾ Ğ´Ğ¾ optimizer.step()
health = check_gradient_health(model)

if not health["healthy"]:
    print("âš ï¸ Gradient issues detected!")
    for issue in health["issues"]:
        print(f"  - {issue}")
```

**Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:**
- `healthy`: bool â€” Ğ²ÑÑ‘ Ğ»Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾
- `issues`: list â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
- `stats`: dict â€” ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° (min, max, mean, std)

---

### GradientStats

```python
@dataclass
class GradientStats:
    min_grad: float
    max_grad: float
    mean_grad: float
    std_grad: float
    num_zero: int
    num_nan: int
    num_inf: int
```

Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ².

---

### TrainingMetrics

```python
@dataclass  
class TrainingMetrics:
    step: int
    loss: float
    learning_rate: float
    gradient_norm: float
    gpu_memory_used: float
    gpu_memory_total: float
```

ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.

---

### TrainingMonitor

```python
class TrainingMonitor:
    def __init__(self, model, check_every: int = 100)
```

ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

```python
from transformers import TrainingMonitor

monitor = TrainingMonitor(model)

# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ summary
summary = monitor.get_model_summary()
print(f"Total params: {summary['total_parameters']}")
print(f"Trainable: {summary['trainable_parameters']}")
```

---

### MonitorCallback

```python
class MonitorCallback(TrainerCallback):
    def __init__(
        self,
        print_model_summary: bool = True,
        log_gpu_memory: bool = True,
        check_gradients: bool = False,
        gradient_check_steps: int = 100
    )
```

Callback Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ `Trainer`.

```python
from transformers import Trainer
from transformers import MonitorCallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[
        MonitorCallback(
            print_model_summary=True,
            log_gpu_memory=True,
            check_gradients=True
        )
    ]
)
```

**Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ callback:**
- ĞŸÑ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ â€” Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
- ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ N ÑˆĞ°Ğ³Ğ¾Ğ² â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ (ĞµÑĞ»Ğ¸ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)
- Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚ GPU memory Ğ² wandb/tensorboard

---

### GPU Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

#### get_gpu_memory_info

```python
def get_gpu_memory_info() -> Dict[str, float]
```

Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ GPU.

```python
from transformers.training_monitor import get_gpu_memory_info

gpu_info = get_gpu_memory_info()
print(f"Used: {gpu_info['used_gb']:.2f} GB")
print(f"Free: {gpu_info['free_gb']:.2f} GB")
print(f"Total: {gpu_info['total_gb']:.2f} GB")
```

---

## ğŸ’¡ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€

```python
from transformers import AutoModelForCausalLM, Trainer, TrainingArguments
from transformers import (
    MonitorCallback,
    print_model_info,
    estimate_model_memory
)

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
model = AutoModelForCausalLM.from_pretrained("model_name")

# ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
print_model_info(model, show_breakdown=True)

memory = estimate_model_memory(model, batch_size=4, sequence_length=2048)
print(f"\nEstimated memory: {memory['total_estimated_gb']:.2f} GB")

# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼
trainer = Trainer(
    model=model,
    args=TrainingArguments(output_dir="./output"),
    train_dataset=dataset,
    callbacks=[
        MonitorCallback(
            check_gradients=True,
            gradient_check_steps=50
        )
    ]
)

trainer.train()
```

---

## âš ï¸ Ğ’Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ñ

1. **GPU:** Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ GPU Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ CUDA
2. **ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:** `check_gradients` Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ overhead
3. **Ğ¡Ğ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ:** Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ»ÑĞ±Ğ¾Ğ¹ PyTorch Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ

---

## ğŸ†• ProgressCallback (v1.0.6)

```python
class ProgressCallback(TrainerCallback):
    def __init__(
        self,
        show_eta: bool = True,
        show_loss: bool = True,
        show_speed: bool = True,
        show_gpu_mem: bool = True,
        bar_width: int = 25,
        use_unicode: bool = True
    )
```

ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€ Ñ ETA Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸. **ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ° tqdm Ğ±ĞµĞ· Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹.**

### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```python
from transformers import Trainer
from transformers.training_monitor import ProgressCallback

trainer = Trainer(
    model=model,
    args=training_args,
    callbacks=[ProgressCallback()]
)
trainer.train()
```

### ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ”¥ TRAINING STARTED                                     â•‘
â•‘  Model: GPT2LMHeadModel                                  â•‘
â•‘  Max Steps: 5000                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step  1250/5000 | [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] | 25.0% | ETA: 15m 32s | 12.4 it/s | loss: 0.4521â†“

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… TRAINING COMPLETE                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Total Steps:                                     5000   â•‘
â•‘  Total Time:                                    20m 15s  â•‘
â•‘  Average Speed:                              4.12 it/s   â•‘
â•‘  Final Loss:                                   0.2134    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹

| ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ | ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|----------|--------------|----------|
| `show_eta` | `True` | ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞµĞµÑÑ Ğ²Ñ€ĞµĞ¼Ñ |
| `show_loss` | `True` | ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ loss Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ |
| `show_speed` | `True` | ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ (it/s) |
| `show_gpu_mem` | `True` | ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ GPU Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ |
| `bar_width` | `25` | Ğ¨Ğ¸Ñ€Ğ¸Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€Ğ° |
| `use_unicode` | `True` | Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Unicode ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ (â–ˆâ–‘) |

### Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹ loss

- **â†“** â€” loss ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ÑÑ (Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾)
- **â†‘** â€” loss ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ (Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ)
- **â†’** â€” loss ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ĞµĞ½

---

## ğŸ†• Smart Training Callbacks (v1.0.7)

### EarlyStoppingCallback

```python
class EarlyStoppingCallback(TrainerCallback):
    def __init__(
        self,
        patience: int = 3,
        metric: str = "eval_loss",
        min_delta: float = 0.0,
        mode: str = "min",
        verbose: bool = True
    )
```

ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°Ñ‘Ñ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒÑÑ.

```python
from transformers.training_monitor import EarlyStoppingCallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[EarlyStoppingCallback(patience=3)]
)
```

**Ğ’Ñ‹Ğ²Ğ¾Ğ´:**
```
ğŸ“Š EarlyStopping: Initial eval_loss=0.5234
ğŸ“ˆ EarlyStopping: eval_loss improved to 0.4521
â³ EarlyStopping: No improvement (1/3)
â³ EarlyStopping: No improvement (2/3)
â³ EarlyStopping: No improvement (3/3)

ğŸ›‘ EARLY STOPPING at epoch 5.0
   Best eval_loss: 0.4521
```

---

### ReduceLROnPlateauCallback

```python
class ReduceLROnPlateauCallback(TrainerCallback):
    def __init__(
        self,
        factor: float = 0.5,
        patience: int = 2,
        min_lr: float = 1e-7,
        metric: str = "eval_loss",
        mode: str = "min",
        verbose: bool = True
    )
```

ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ learning rate Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ğ³Ğ½Ğ°Ñ†Ğ¸Ğ¸.

```python
from transformers.training_monitor import ReduceLROnPlateauCallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[ReduceLROnPlateauCallback(factor=0.5, patience=2)]
)
```

---

### BestModelCallback

```python
class BestModelCallback(TrainerCallback):
    def __init__(
        self,
        save_path: str = "./best_model",
        metric: str = "eval_loss",
        mode: str = "min",
        verbose: bool = True
    )
```

ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ.

```python
from transformers.training_monitor import BestModelCallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[BestModelCallback(save_path="./best")]
)
```

**Ğ’Ñ‹Ğ²Ğ¾Ğ´:**
```
ğŸ’¾ BEST MODEL SAVED: eval_loss=0.4521
   Path: ./best
   Step: 1500

âœ… Best model summary:
   eval_loss: 0.4521
   Saved at step: 1500
   Path: ./best
```
