# üî® Transformers Forge - Changelog

–í—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ.

–§–æ—Ä–º–∞—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ [Keep a Changelog](https://keepachangelog.com/ru/1.0.0/),
–∏ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è [–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è](https://semver.org/lang/ru/).

---

## [1.1.1] - 2025-12-19 ‚Äî LR Finder

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **LR Finder** ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä learning rate
  - –ù–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–æ–¥–∞ Leslie Smith (2015)
  - –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π LR sweep —Å –∞–Ω–∞–ª–∏–∑–æ–º loss
  - –ì—Ä–∞—Ñ–∏–∫ loss vs LR
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
  ```python
  from transformers import LRFinder, find_optimal_lr
  
  optimal_lr = find_optimal_lr(model, train_dataloader)
  ```

### üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è LR Finder: `docs/api/lr_finder.md`
- –î–æ–±–∞–≤–ª–µ–Ω —ç–∫—Å–ø–æ—Ä—Ç `LRFinder` –∏ `find_optimal_lr` –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–æ–¥—É–ª—è

### üß™ –¢–µ—Å—Ç—ã

- 7 –Ω–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤ –¥–ª—è LR Finder

---

## [1.1.0] - 2025-12-19 ‚Äî Honest Warnings & Better UX

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **`get_args_dict()`** ‚Äî –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è Training Presets
  - –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç `accelerate`
  - –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ –∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
  
### üîß –£–ª—É—á—à–µ–Ω–∏—è

- **–ß–µ—Å—Ç–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è EMA**
  - Warning –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ EMA –Ω–∞ –º–æ–¥–µ–ª—è—Ö <1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
  - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —á—Ç–æ EMA —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –Ω–∞ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª—è—Ö –∏ –¥–ª–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏
  - –°—Å—ã–ª–∫–∞ –Ω–∞ `docs/RESEARCH.md` –¥–ª—è –¥–µ—Ç–∞–ª–µ–π

- **Graceful handling –¥–ª—è accelerate**
  - –ü–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ `accelerate>=1.1.0`
  - –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã `get_args_dict()`
  - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ

### üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- –ß–µ—Å—Ç–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π EMA –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- –û–±–Ω–æ–≤–ª—ë–Ω RESEARCH.md —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

### üß™ –¢–µ—Å—Ç—ã

- –î–æ–±–∞–≤–ª–µ–Ω —Ç–µ—Å—Ç –¥–ª—è `get_args_dict()`
- 111+ unit —Ç–µ—Å—Ç–æ–≤ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.9] - 2025-12-19 ‚Äî Interactive Model Manager

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **InteractiveModelManager** ‚Äî –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–æ–Ω—Å–æ–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏
  - –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö HuggingFace –º–æ–¥–µ–ª–µ–π (–∏—Å–∫–ª—é—á–∞–µ—Ç GGUF)
  - –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (ChatML JSONL)
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å –∞–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–æ–π (trl, datasets, peft)
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –∏ VRAM
  - Fine-tune Wizard —Å –ø–æ–ª–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π

- **Fine-tune Wizard** ‚Äî –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –º–∞—Å—Ç–µ—Ä –¥–æ–æ–±—É—á–µ–Ω–∏—è
  - –†–µ–∂–∏–º **Auto** ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π
  - –ü—Ä–µ—Å–µ—Ç—ã **A/B/C** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (LR, batch, epochs)
  - –í–∞–ª–∏–¥–∞—Ü–∏—è —Å –¥–∏—Å–∫–ª–µ–π–º–µ—Ä–∞–º–∏ –∏ –¥–≤–æ–π–Ω—ã–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
  - –í—ã–±–æ—Ä output directory
  - LoRA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

- **–ê–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π**
  - [A] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (pip install)
  - [M] –í—Ä—É—á–Ω—É—é (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É)

- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Training Callbacks**
  - ProgressCallback ‚Äî –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
  - EarlyStoppingCallback ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (Y/N)
  - TrainingReportCallback ‚Äî –æ—Ç—á—ë—Ç –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è

### üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers.interactive import InteractiveModelManager

manager = InteractiveModelManager(
    models_dir="./models",
    datasets_dir="./datasets"
)
manager.run()
```

### üìù –ü—Ä–∏–º–µ—Ä—ã UI

```
‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ê –ü–ê–†–ê–ú–ï–¢–†–û–í
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üí° –ü–û–î–°–ö–ê–ó–ö–ê                                                    ‚îÇ
‚îÇ  ‚Ä¢ –í–≤–µ–¥–∏—Ç–µ 'Auto' ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏   ‚îÇ
‚îÇ  ‚Ä¢ –ò–ª–∏ –≤—ã–±–∏—Ä–∞–π—Ç–µ –ø—Ä–µ—Å–µ—Ç—ã A/B/C –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞           ‚îÇ
‚îÇ  ‚Ä¢ B = —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π (‚≠ê)                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Learning Rate:
   [A] 5e-5  ‚Äî –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π (–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
   [B] 2e-5  ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π (‚≠ê)
   [C] 1e-5  ‚Äî –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
```

### üõ°Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫

```
‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
‚îÇ  Learning Rate: 0.001
‚îÇ  –ü—Ä–æ–±–ª–µ–º–∞: –í—ã—Å–æ–∫–∏–π LR (> 1e-3) ‚Äî –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
‚îÇ  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 1e-5 –¥–æ 5e-5

–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? [y/N]: n

üìñ –ü–û–î–†–û–ë–ù–û–ï –û–ë–™–Ø–°–ù–ï–ù–ò–ï
‚îÇ  Learning rate –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä —à–∞–≥–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–æ–≤.
‚îÇ  –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π LR –ø—Ä–∏–≤–æ–¥–∏—Ç –∫:
‚îÇ    ‚Ä¢ –•–∞–æ—Ç–∏—á–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º –≤–µ—Å–æ–≤
‚îÇ    ‚Ä¢ Loss –º–æ–∂–µ—Ç —Ä–∞—Å—Ç–∏ –≤–º–µ—Å—Ç–æ —Å–Ω–∏–∂–µ–Ω–∏—è
‚îÇ    ‚Ä¢ –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç '—Ä–∞–∑—É—á–∏—Ç—å—Å—è'
```

### üß™ –¢–µ—Å—Ç—ã

- 12 unit —Ç–µ—Å—Ç–æ–≤ –¥–ª—è InteractiveModelManager
- 98+ —Ç–µ—Å—Ç–æ–≤ –≤—Å–µ–≥–æ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.8] - 2025-12-19 ‚Äî Training Reports

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **TrainingReportCallback** ‚Äî –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
  - –°–æ–∑–¥–∞—ë—Ç Markdown –æ—Ç—á—ë—Ç —Å –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
  - **Interactive Model Naming** ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
  - –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è (—Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞, —Ü–∏—Ñ—Ä—ã, -, _)
  - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç: loss –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü, improvement %, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è

### üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers.training_monitor import TrainingReportCallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[TrainingReportCallback(output_path="./report.md")]
)
```

### üìù –ü—Ä–∏–º–µ—Ä –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è

```
============================================================
üìù –ò–ú–ï–ù–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –û–¢–ß–Å–¢–ê
============================================================
   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: Qwen2ForCausalLM

   [1] –û—Å—Ç–∞–≤–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
   [2] –ó–∞–¥–∞—Ç—å —Å–≤–æ—ë –Ω–∞–∑–≤–∞–Ω–∏–µ
============================================================

   –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: Ivan-3B
   ‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ: Ivan-3B
```

### üß™ –¢–µ—Å—Ç—ã

- 98 unit —Ç–µ—Å—Ç–æ–≤ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.7] - 2025-12-19 ‚Äî Smart Training Callbacks

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **EarlyStoppingCallback** ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏
  - –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç eval_loss –∏–ª–∏ –ª—é–±—É—é –º–µ—Ç—Ä–∏–∫—É
  - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π patience (—Ç–µ—Ä–ø–µ–Ω–∏–µ)
  - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ min_delta –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è
  - –†–µ–∂–∏–º—ã "min" –∏ "max"
  - **Interactive —Ä–µ–∂–∏–º** ‚Äî —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç Y/N –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π

- **ReduceLROnPlateauCallback** ‚Äî –°–Ω–∏–∂–µ–Ω–∏–µ LR –ø—Ä–∏ —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–Ω–∏–∂–∞–µ—Ç learning rate –ø—Ä–∏ plateau
  - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π factor (0.5 = –ø–æ–ª–æ–≤–∏–Ω–∞)
  - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π LR –ø–æ—Ä–æ–≥

- **BestModelCallback** ‚Äî –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
  - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏
  - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç tokenizer –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
  - –õ–æ–≥–∏—Ä—É–µ—Ç —à–∞–≥ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏

### üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers import Trainer
from transformers.training_monitor import (
    EarlyStoppingCallback,
    ReduceLROnPlateauCallback,
    BestModelCallback
)

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[
        EarlyStoppingCallback(patience=3),
        ReduceLROnPlateauCallback(factor=0.5, patience=2),
        BestModelCallback(save_path="./best_model")
    ]
)
```

### üß™ –¢–µ—Å—Ç—ã

- 92 unit —Ç–µ—Å—Ç–∞ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.6] - 2025-12-19 ‚Äî Rich Training Progress + Utilities

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **ProgressCallback** ‚Äî –ö—Ä–∞—Å–∏–≤—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å ETA –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
  - –í–∏–∑—É–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
  - ETA (–ø—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è)
  - –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (steps/sec)
  - GPU –ø–∞–º—è—Ç—å
  - –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è loss (‚Üì‚Üë)
  - –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏

- **`get_layer_names(model)`** ‚Äî –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–º—ë–Ω –≤—Å–µ—Ö —Å–ª–æ—ë–≤ –º–æ–¥–µ–ª–∏
  - –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏
  - –ü–∞—Ä–∞–º–µ—Ç—Ä `include_params=True` –≤–∫–ª—é—á–∞–µ—Ç –∏–º–µ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

- **`estimate_training_time(model, ...)`** ‚Äî –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è
  - –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –¥–æ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
  - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç formatted —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "2h 15m 30s"

- **`print_model_summary(model)`** ‚Äî –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏ (–∫–∞–∫ –≤ Keras)
  - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ —Å–ª–æ–∏ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
  - –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç trainable/frozen —Å—Ç–∞—Ç—É—Å
  - –û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏ –º–æ–¥–µ–ª–∏

### üìà –ü—Ä–∏–º–µ—Ä ProgressCallback

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üî• TRAINING STARTED                                     ‚ïë
‚ïë  Model: GPT2LMHeadModel                                  ‚ïë
‚ïë  Max Steps: 5000                                         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Step  1250/5000 | [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] | 25.0% | ETA: 15m 32s | 12.4 it/s | loss: 0.4521‚Üì

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ‚úÖ TRAINING COMPLETE                                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  Total Steps:                                     5000   ‚ïë
‚ïë  Total Time:                                    20m 15s  ‚ïë
‚ïë  Average Speed:                              4.12 it/s   ‚ïë
‚ïë  Final Loss:                                   0.2134    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers import Trainer
from transformers.training_monitor import ProgressCallback
from transformers.layer_utils import (
    get_layer_names,
    estimate_training_time,
    print_model_summary
)

# ProgressCallback
trainer = Trainer(
    model=model,
    args=training_args,
    callbacks=[ProgressCallback()]
)
trainer.train()

# Utility functions
names = get_layer_names(model)
estimate = estimate_training_time(model, 10000, 8, 3)
print_model_summary(model)
```

### üß™ –¢–µ—Å—Ç—ã

- 82 unit —Ç–µ—Å—Ç–∞ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.5] - 2025-12-19 ‚Äî Interactive Config Validation

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤** ‚Äî –î–∏–∞–ª–æ–≥ Y/N/A –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º
  - `validate()` ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã
  - `auto_fix()` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
  - `validate_config()` ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥
  
### üîß –ü—Ä–æ–≤–µ—Ä–∫–∏

| –ü—Ä–æ–≤–µ—Ä–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|
| **bf16/fp16 –Ω–∞ CPU** | –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ + fallback |
| **–í—ã—Å–æ–∫–∏–π LR** | > 1e-2 ‚Üí warning |
| **–ù–∏–∑–∫–∏–π LR** | < 1e-7 ‚Üí warning |
| **warmup –∫–æ–Ω—Ñ–ª–∏–∫—Ç** | ratio + steps –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ |
| **–ë–æ–ª—å—à–æ–π batch** | > 128 ‚Üí OOM warning |

### üìà –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```python
from transformers.training_presets import get_preset, validate_config

preset = get_preset("qlora", output_dir="./model")

if validate_config(preset, interactive=True):
    args = preset.get_training_args()
    trainer.train()
```

### üß™ –¢–µ—Å—Ç—ã

- 70 unit —Ç–µ—Å—Ç–æ–≤ (100% –ø—Ä–æ—Ö–æ–¥—è—Ç)

---

## [1.0.4] - 2025-12-18 ‚Äî Dynamic EMA

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **Dynamic EMA Decay** ‚Äî Decay –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Ç—ë—Ç –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
  - –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏—è EMA –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö
  - `compute_dynamic_decay()` ‚Äî –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ decay
  - –¢—Ä–∏ schedule: `linear`, `cosine`, `exponential`
  - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ `total_steps` –∏–∑ `TrainerState`

### üìà –£–ª—É—á—à–µ–Ω–∏—è

- **EMACallback** —Ç–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç dynamic decay:
  ```python
  EMACallback(
      use_dynamic_decay=True,
      min_decay=0.9,
      max_decay=0.999,
      decay_schedule="linear"
  )
  ```
  
### üî¨ Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | Static EMA | Dynamic EMA |
|---------|------------|-------------|
| EMA Win Rate | 17% | **50%** |
| –û—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ Step 50 | -120% | **-9%** |
| Improvement | -6.1% | **-1.9%** |

---

## [1.0.3] - 2025-12-18 ‚Äî CI/CD Automation

### ü§ñ CI/CD

- **GitHub Actions workflow** ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ unit —Ç–µ—Å—Ç–æ–≤
  - –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ push –∏ pull request –≤ main
  - –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ Python 3.10 –∏ 3.11
  - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ pip –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
- **Tests badge** ‚Äî –°—Ç–∞—Ç—É—Å —Ç–µ—Å—Ç–æ–≤ –≤–∏–¥–µ–Ω –≤ README
- **Path filtering** ‚Äî –¢–µ—Å—Ç—ã –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ src/ –∏–ª–∏ tests/

### üêõ Bug Fixes

- **EMA warmup reinitialization** ‚Äî –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –±–∞–≥ –≤ `EMACallback`
  - **–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ—Å–ª–µ warmup –ø–µ—Ä–∏–æ–¥–∞ EMA —Å–æ–¥–µ—Ä–∂–∞–ª —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞
  - **–†–µ—à–µ–Ω–∏–µ:** EMA –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Ç–µ–∫—É—â–∏–º–∏ –≤–µ—Å–∞–º–∏ –ø–æ—Å–ª–µ warmup
  - **–≠—Ñ—Ñ–µ–∫—Ç:** EMA —Ç–µ–ø–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å `update_after_step > 0`

### üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **docs/RESEARCH.md** ‚Äî –¢–µ–æ—Ä–∏—è –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π
  - –ù–∞—É—á–Ω—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (Polyak 1992, Dettmers 2023 –∏ –¥—Ä.)
  - –°—Ç–∞—Ç—É—Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö benchmarks
  - –ß–µ—Å—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: EMA —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –Ω–∞ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª—è—Ö

### üî¨ Benchmarks

- **benchmarks/ema_benchmark.py** ‚Äî –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ EMA
  - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏)
  - –ß–µ—Å—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥—ã

---

## [1.0.2] - 2025-12-18 ‚Äî Tests Verified

### ‚úÖ –¢–µ—Å—Ç—ã

- **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã —Ç–µ—Å—Ç—ã** ‚Äî –≤—Å–µ unit —Ç–µ—Å—Ç—ã —Ç–µ–ø–µ—Ä—å –ø—Ä–æ—Ö–æ–¥—è—Ç (100%)
- `test_ema.py` ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–π API
- `test_layer_utils.py` ‚Äî –≤—Å–µ —Ç–µ—Å—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç
- `test_training_presets.py` ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–π API
- `test_training_monitor.py` ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π

### üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

- –¢–µ—Å—Ç—ã —Ç–µ–ø–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∞–ª—å–Ω—ã–º —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º —Ñ—É–Ω–∫—Ü–∏–π
- –£–±—Ä–∞–Ω—ã –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã –∏–∑ —Ç–µ—Å—Ç–æ–≤

---

## [1.0.1] - 2025-12-18 ‚Äî –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –¢–µ—Å—Ç—ã

### üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **docs/index.md** ‚Äî –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- **docs/api/** ‚Äî API Reference –¥–ª—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π:
  - `ema.md` ‚Äî –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è EMA
  - `layer_utils.md` ‚Äî –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Layer Utils
  - `training_presets.md` ‚Äî –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Training Presets
  - `training_monitor.md` ‚Äî –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Training Monitor
- **docs/tutorials/** ‚Äî –ì–∞–π–¥—ã –∏ tutorials:
  - `quickstart.md` ‚Äî –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
  - `ema_guide.md` ‚Äî –ü–æ–¥—Ä–æ–±–Ω—ã–π –≥–∞–π–¥ –ø–æ EMA
  - `finetuning.md` ‚Äî –ü–æ–ª–Ω—ã–π –≥–∞–π–¥ –ø–æ fine-tuning

### üíª –ü—Ä–∏–º–µ—Ä—ã

- **examples/forge_examples/** ‚Äî –†–∞–±–æ—á–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞:
  - `ema_example.py` ‚Äî –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è EMA
  - `layer_freezing_example.py` ‚Äî –ü—Ä–∏–º–µ—Ä –∑–∞–º–æ—Ä–æ–∑–∫–∏ —Å–ª–æ—ë–≤
  - `training_presets_example.py` ‚Äî –ü—Ä–∏–º–µ—Ä Training Presets

### üß™ –¢–µ—Å—Ç—ã

- **tests/forge/** ‚Äî Unit —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π:
  - `test_ema.py` ‚Äî –¢–µ—Å—Ç—ã EMA
  - `test_layer_utils.py` ‚Äî –¢–µ—Å—Ç—ã Layer Utils
  - `test_training_presets.py` ‚Äî –¢–µ—Å—Ç—ã Training Presets
  - `test_training_monitor.py` ‚Äî –¢–µ—Å—Ç—ã Training Monitor

### üèõÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

- **ROADMAP.md** ‚Äî –ü–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–µ–∫—Ç–∞
- **GOVERNANCE.md** ‚Äî –ú–æ–¥–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
- **.github/ISSUE_TEMPLATE/** ‚Äî –®–∞–±–ª–æ–Ω—ã –¥–ª—è Issues:
  - `bug_report.md`
  - `feature_request.md`
  - `question.md`

---

## [1.0.0] - 2025-12-18 ‚Äî –ü–µ—Ä–≤—ã–π —Ä–µ–ª–∏–∑ Transformers Forge!

### ‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (New Features)

#### Training Monitor Module
- **–§–∞–π–ª:** `src/transformers/training_monitor.py`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ù–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
  - `count_parameters()` ‚Äî –ø–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (total/trainable/frozen)
  - `get_parameter_breakdown()` ‚Äî –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å–ª–æ—è–º
  - `estimate_model_memory()` ‚Äî –æ—Ü–µ–Ω–∫–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
  - `get_gpu_memory_info()` ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –ø–∞–º—è—Ç–∏
  - `check_gradient_health()` ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (NaN, Inf, vanishing, exploding)
  - `TrainingMonitor` ‚Äî –∫–ª–∞—Å—Å –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
  - `MonitorCallback` ‚Äî callback –¥–ª—è Trainer —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
  - `print_model_info()` / `print_gpu_status()` ‚Äî –±—ã—Å—Ç—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
from transformers.training_monitor import TrainingMonitor, MonitorCallback

# –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏
monitor = TrainingMonitor(model)
monitor.print_model_summary()

# –° Trainer
trainer = Trainer(model=model, callbacks=[MonitorCallback()])
```

#### GitHub Actions CI/CD –¥–ª—è Enhanced –≤–µ—Ä—Å–∏–∏
- **–§–∞–π–ª—ã:** `.github/workflows/enhanced-*.yml`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ù–∞–±–æ—Ä –ª—ë–≥–∫–∏—Ö CI/CD workflows –¥–ª—è Enhanced –≤–µ—Ä—Å–∏–∏
- **Workflows:**
  - `enhanced-code-quality.yml` ‚Äî Lint (Ruff), –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤, –≤–µ—Ä—Å–∏–π, —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
  - `enhanced-tests.yml` ‚Äî –¢–µ—Å—Ç—ã GenerationConfig, training_monitor, –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∏–∫—Å–æ–≤
  - `enhanced-release.yml` ‚Äî –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–ª–∏–∑–∞, —Å–±–æ—Ä–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
  - –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö GitHub-hosted runners (–±–µ–∑ GPU)
  - –ù–µ —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ–∫—Ä–µ—Ç–æ–≤ HuggingFace
  - –ë—ã—Å—Ç—Ä–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (~3-5 –º–∏–Ω—É—Ç)

#### Training Presets Module
- **–§–∞–π–ª:** `src/transformers/training_presets.py`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ì–æ—Ç–æ–≤—ã–µ, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM
- **Presets:**
  - `SFTPreset` ‚Äî Supervised Fine-Tuning —Å NEFTune
  - `LoRAPreset` ‚Äî LoRA fine-tuning (PEFT)
  - `QLoRAPreset` ‚Äî 4-bit Quantized LoRA  
  - `DPOPreset` ‚Äî Direct Preference Optimization
  - `MemoryEfficientPreset` ‚Äî –î–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π GPU –ø–∞–º—è—Ç–∏
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
  - –ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU/CPU –∏ bf16 –ø–æ–¥–¥–µ—Ä–∂–∫–∏
  - –ì–æ—Ç–æ–≤—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è PEFT (LoraConfig) –∏ BitsAndBytes
  - Registry –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö presets
  - Quick-—Ñ—É–Ω–∫—Ü–∏–∏: `quick_sft_args()`, `quick_lora_args()`

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
from transformers.training_presets import get_preset

# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
preset = get_preset("lora", lora_r=16)
training_args = preset.get_training_args()
lora_config = preset.get_lora_config()
```

#### Layer Utilities Module
- **–§–∞–π–ª:** `src/transformers/layer_utils.py`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ—è–º–∏ (–∑–∞–º–æ—Ä–æ–∑–∫–∞/—Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞)
- **–§—É–Ω–∫—Ü–∏–∏:**
  - `freeze_first_n_layers()` ‚Äî –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –ø–µ—Ä–≤—ã–µ N —Å–ª–æ—ë–≤ (LP-LoRA —Å—Ç–∏–ª—å)
  - `freeze_except_last_n()` ‚Äî –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤—Å—ë –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N
  - `freeze_embeddings()` ‚Äî –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
  - `get_trainable_params()` / `get_frozen_percentage()` ‚Äî –∞–Ω–∞–ª–∏–∑
  - `print_layer_status()` ‚Äî —Ç–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç—É—Å–∞ —Å–ª–æ—ë–≤
  - `GradualUnfreezer` ‚Äî –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è —Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞ –¥–ª—è transfer learning
  - `setup_lp_lora_style()` ‚Äî –±—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LP-LoRA
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
  - 100% –±–µ–∑–æ–ø–∞—Å–Ω–æ ‚Äî –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
  - –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –¥–æ 50%+ (–º–µ–Ω—å—à–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤)
  - –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
from transformers import freeze_first_n_layers, get_frozen_percentage

freeze_first_n_layers(model, n=16)  # LP-LoRA —Å—Ç–∏–ª—å
print(f"Frozen: {get_frozen_percentage(model):.1f}%")
```

#### EMA (Exponential Moving Average) Module
- **–§–∞–π–ª:** `src/transformers/ema.py`
- **–û–ø–∏—Å–∞–Ω–∏–µ:** –°–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª—É—á—à–µ–π generalization
- **–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
  - `EMACallback` ‚Äî Callback –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Trainer
  - `EMAModel` ‚Äî –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è EMA
  - `compute_optimal_decay()` ‚Äî –†–∞—Å—á—ë—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ decay
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
  - **+1-3% –Ω–∞ eval –º–µ—Ç—Ä–∏–∫–∞—Ö** (—Ç–∏–ø–∏—á–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ)
  - –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
  - –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏—è–º–∏ (Polyak averaging, 1990+)
  - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ SOTA: Stable Diffusion, DALL-E

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
from transformers import Trainer
from transformers.ema import EMACallback

trainer = Trainer(
    model=model,
    args=args,
    callbacks=[EMACallback(decay=0.999)]
)
trainer.train()

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å EMA –≤–µ—Å–∞ (–±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ)
ema_callback.apply_ema(model)
```

### üêõ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–æ–≤ (Bug Fixes)

#### Fix #1: TvpConfig –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `type_vocab_size` (Issue #42925)
- **–§–∞–π–ª:** `src/transformers/models/tvp/configuration_tvp.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** `TvpConfig` –Ω–µ –∏–º–µ–ª –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `type_vocab_size`, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ `AttributeError` –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º.
- **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `type_vocab_size=2` –≤ `__init__` –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.

#### Fix #2: Qwen2VLImageProcessor –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä `size` (Issue #42910)
- **–§–∞–π–ª:** `src/transformers/models/qwen2_vl/image_processing_qwen2_vl.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** –ü–∞—Ä–∞–º–µ—Ç—Ä `size` –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–ª—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑-–∑–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ª–æ–≥–∏–∫–∏ `if/else`.
- **–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ‚Äî —Ç–µ–ø–µ—Ä—å —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π `size` —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.

#### Fix #3: ConditionalDetr —Ç–µ—Ä—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª–∞—Å—Å –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (Issue #42679)
- **–§–∞–π–ª—ã:** 
  - `src/transformers/models/conditional_detr/image_processing_conditional_detr.py`
  - `src/transformers/models/conditional_detr/image_processing_conditional_detr_fast.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** –ú–µ—Ç–æ–¥ `post_process_semantic_segmentation` –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É–¥–∞–ª—è–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª–∞—Å—Å (`[..., :-1]`), —á—Ç–æ –±—ã–ª–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ DETR (–∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç null class), –Ω–æ Conditional DETR –Ω–µ –∏–º–µ–µ—Ç null class.
- **–†–µ—à–µ–Ω–∏–µ:** –£–±—Ä–∞–Ω–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å—Ä–µ–∑–∞–Ω–∏–µ, –≤—Å–µ –∫–ª–∞—Å—Å—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è.

#### Fix #4: OneFormerProcessor `task_inputs` –Ω–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ (Issue #42722)
- **–§–∞–π–ª:** `src/transformers/models/oneformer/processing_oneformer.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** `task_inputs` –æ—Å—Ç–∞–≤–∞–ª–∏—Å—å –Ω–∞ CPU –¥–∞–∂–µ –∫–æ–≥–¥–∞ `pixel_values` –±—ã–ª–∏ –Ω–∞ GPU, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ –æ—à–∏–±–∫–µ device mismatch.
- **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ `task_inputs` —Å `pixel_values`.

#### Fix #5: SAM HQ —Ç–µ—Å—Ç—ã –ø–∞–¥–∞—é—Ç –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è `set_seed()` (Issue #42890)
- **–§–∞–π–ª:** `tests/models/sam_hq/test_modeling_sam_hq.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –∏–º–µ–ª–∏ `set_seed()`, —á—Ç–æ –¥–µ–ª–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–º–∏.
- **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω `setUp` –º–µ—Ç–æ–¥ —Å `set_seed(0)` –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.

#### Fix #6: SiglipModel –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `hidden_states` (Issue #42759)
- **–§–∞–π–ª:** `src/transformers/models/siglip/modeling_siglip.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** `SiglipTextTransformer` –Ω–µ –∏–º–µ–ª –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ `@check_model_inputs`, –ø–æ—ç—Ç–æ–º—É `output_hidden_states=True` –Ω–µ —Ä–∞–±–æ—Ç–∞–ª.
- **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä `@check_model_inputs(tie_last_hidden_states=False)`.

#### Fix #7: GenerationConfig –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —è–≤–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (Issue #42762)
- **–§–∞–π–ª—ã:** 
  - `src/transformers/generation/configuration_utils.py`
  - `src/transformers/generation/utils.py`
  - `tests/generation/test_configuration_utils.py`
- **–ü—Ä–æ–±–ª–µ–º–∞:** –õ–æ–≥–∏–∫–∞ —Å–ª–∏—è–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤ –Ω–µ –º–æ–≥–ª–∞ –æ—Ç–ª–∏—á–∏—Ç—å —è–≤–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –∑–∞–¥–∞–ª `temperature=1.0`, –∞ –º–æ–¥–µ–ª—å –∏–º–µ–ª–∞ `temperature=1e-06`, –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–ª–æ—Å—å.
- **–†–µ—à–µ–Ω–∏–µ:** 
  - –î–æ–±–∞–≤–ª–µ–Ω –∞—Ç—Ä–∏–±—É—Ç `_explicitly_set_attrs` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —è–≤–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
  - –ò–∑–º–µ–Ω–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ —Å–ª–∏—è–Ω–∏—è ‚Äî —è–≤–Ω–æ –∑–∞–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è.
  - –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–µ—Å—Ç—ã –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏.
- **–í–∞–∂–Ω–æ –¥–ª—è:** RLHF, DPO, GRPO, TRL training ‚Äî —Ç–µ–ø–µ—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è.

---

## –ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone https://github.com/YOUR_USERNAME/transformers-enhanced.git
cd transformers-enhanced

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
pip install -e .
```

---

## –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å

- **–ë–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è:** transformers 5.0.0.dev0
- **Python:** 3.9+
- **PyTorch:** 2.0+

---

## –ê–≤—Ç–æ—Ä—ã

- Community Enhanced Version
- –û—Ä–∏–≥–∏–Ω–∞–ª: Hugging Face Team
